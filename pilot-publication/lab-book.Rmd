# Lab book for the TERN pilot publication

This file includes code and scripts used to experiment and explore with the TERN pilot data. 

```{r setup}
noacsr::source_all_functions()
load_packages()
```

## Compare directly observed with retrospective data

```{r}
## Import data
data <- readr::read_csv(Sys.getenv("DATA_DIR"))

## Import codebook
codebook.arguments <- lapply(
    c("URL", "UID", "USERNAME", "PASSWORD"),
    function(x) Sys.getenv(paste0("KOBO_", x))
)
codebook <- do.call(noacsr::kobo_get_project_codebook, codebook.arguments)

## Prepare data
data <- prepare_data(data, codebook)

## Get variables to compare
retrospective.variables <- names(data)[grep("_r__", names(data), fixed = TRUE)]
directly.observed.variables <- retrospective.variables %>%
    stringr::str_replace_all(pattern = "\\_r\\_\\_", replacement = "\\_\\_") %>%
    stringr::str_replace_all(pattern = "\\_r$", replacement = "")

## Keep only observations with any retrospective data
data <- data[apply(data[, retrospective.variables], 1, function(row) any(!is.na(row))), ] %>%
    as_tibble()

## Extract retrospective and directly observed data
retrospective.data <- data[, retrospective.variables]
colnames(retrospective.data) <- directly.observed.variables
directly.observed.data <- data[, directly.observed.variables]
retrospective.data$collection.mode <- "Retrospective"
directly.observed.data$collection.mode <- "Directly observed"

## Make sure column classes are the same in both datasets
retrospective.data[] <- lapply(names(retrospective.data), function(column.name) {
    retrospective.column <- retrospective.data[[column.name]]
    directly.observed.column <- directly.observed.data[[column.name]]
    retrospective.class <- class(retrospective.column)
    directly.observed.class <- class(directly.observed.column)
    class.function <- paste0("as.", directly.observed.class)
    if ("POSIXct" %in% directly.observed.class) {
        class.function <- "as.POSIXct"
    }
    if (retrospective.class != directly.observed.class) {
        retrospective.column <- do.call(class.function, list(retrospective.column))
    }
    return(retrospective.column)
})

## Merge data
merged.data <- bind_rows(retrospective.data, directly.observed.data)
```


## Import bootstrapped outcome results and generate confidence intervals

```{r}
## Load bootstrapped outcome results
bootstrapped.outcome.results <- readRDS(file.path("out", "bootstrapped-outcome-results.Rds"))
str(bootstrapped.outcome.results, max.level = 1)

## Calculate confidence intervals
bootstrapped.outcome.results.ci <- calculate_bootstrap_cis(bootstrapped.outcome.results)

## Combine point estimates with confidence intervals
outcome.results <- list(
    point.estimates = bootstrapped.outcome.results$t0,
    confidence.intervals = bootstrapped.outcome.results.ci
)
saveRDS(outcome.results, file = file.path("outcome-results.Rds"))
```

## Import saved outcome results and create outcome tables

```{r}
## Load outcome results
outcome.results <- readRDS("outcome-results.Rds")

## Extract cell references
cell.references <- names(outcome.results$point.estimates)

table.names <- strsplit(cell.references, split = "\\|\\|\\.") %>%
    lapply(function(table.name) table.name[1]) %>%
    unique()

ci.levels <- outcome.results$confidence.intervals[[2]][, 1]

## Combine point estimates and confidence intervals into a single table
combined.outcome.results <- lapply(ci.levels, function(ci.level) {
    lapply(cell.references, function(cell.reference) {
        point.estimate <- outcome.results$point.estimates[[cell.reference]]
        ci.data <- outcome.results$confidence.intervals[[cell.reference]]
        ci <- ci.data[ci.data[, "level"] == ci.level, c("lower", "upper")]
        combined <- NA
        if (!all(is.na(ci))) {
            combined <- round(c(point.estimate, ci), 2)
            combined <- paste0(combined[1], " (", combined[2], ", ", combined[3], ")")
        }
        return(combined)
    }) %>%
        setNames(cell.references)
}) %>%
    setNames(paste0("ci.level.", ci.levels))

## Create outcome tables
create_ci_level_tables <- function(table.name, ci.data) {
    ## Extract table data
    table.data <- ci.data[grep(table.name, names(ci.data), fixed = TRUE)]
    column.names <- strsplit(names(table.data), split = "\\|\\|\\.") %>%
        lapply(function(column) column[2]) %>%
        unique() %>%
        stringr::str_replace_all(pattern = "\\|\\|column\\:\\:", replacement = "") %>%
        stringr::str_replace_all(pattern = "\\*\\*", replacement = "")
    row.names <- strsplit(names(table.data), split = "\\|\\|\\.") %>%
        lapply(function(row) row[3]) %>%
        unique() %>%
        stringr::str_replace_all(pattern = "\\|\\|row\\:\\:index\\:[0-9]*\\:\\:", replacement = "") %>%
        stringr::str_replace_all(pattern = "\\|\\|", replacement = "")

    ## Replace outcome names with labels
    all.outcomes <- all_outcomes()
    outcomes.column.list <- lapply(row.names, function(row.name) {
        new.row.name <- row.name
        index <- FALSE
        if (!is.null(all.outcomes[[row.name]])) {
            new.row.name <- all.outcomes[[row.name]]$label
            index <- TRUE
        }
        return(list(row.name = new.row.name, index = index))
    })
    outcomes.column.index <- sapply(outcomes.column.list, function(outcomes.column) outcomes.column$index)
    outcomes.column <- sapply(outcomes.column.list, function(outcomes.column) outcomes.column$row.name)

    ## Create table
    ci.table <- matrix(table.data, ncol = length(column.names)) %>%
        tibble::as_tibble(.name_repair = "minimal") %>%
        tibble::add_column(outcomes.column, .before = 1, .name_repair = "minimal") %>%
        setNames(c("Outcome", column.names))

    ## Replace NA with empty string
    ci.table[] <- lapply(ci.table, function(column) {
        column[is.na(column)] <- ""
        return(column)
    })

    ## Convert table to gt
    ci.table <- ci.table %>%
        gt::gt() %>%
        gt::tab_style(
            style = gt::cell_text(weight = "bold"),
            locations = gt::cells_body(
                columns = c(Outcome),
                rows = outcomes.column.index
            )
        ) %>%
        gt::tab_style(
            style = gt::cell_text(weight = "bold"),
            locations = gt::cells_column_labels()
        )

    ## Return table
    return(ci.table)
}

tables <- lapply(
    combined.outcome.results, function(ci.data) {
        {
            lapply(table.names, create_ci_level_tables, ci.data = ci.data)
        } %>%
            setNames(stringr::str_replace(table.names, pattern = "\\|\\|table\\:\\:", replacement = ""))
    }
)
```

## Save tables to file

```{r}
## Save tables to file
document.string <- lapply(
    names(tables), function(ci.level.tables.name) {
        ## Extract confidence level as percentage
        ci.level <- stringr::str_remove(ci.level.tables.name, pattern = "ci\\.level\\.") %>%
            as.numeric() %>%
            scales::percent()
        ci.level.tables <- tables[[ci.level.tables.name]]
        paste0(
            "# ", ci.level, " confidence level\n\n",
            lapply(names(ci.level.tables), function(ci.level.table.name) {
                ci.level.table <- ci.level.tables[[ci.level.table.name]]
                paste0(
                    "## ", ci.level.table.name, "\n\n",
                    "\`\`\`{r, echo = FALSE} \n\n",
                    "tables[[\"", ci.level.tables.name, "\"]][[\"", ci.level.table.name, "\"]]", "\n\n",
                    "\`\`\`\n\n"
                )
            }) %>%
                paste0(collapse = "\n\n")
        )
    }
) %>%
    unlist() %>%
    paste0(collapse = "\n\n")

## Write document string to file
fileConn <- file("outcome-tables.Rmd")
writeLines(document.string, fileConn)
close(fileConn)

## Create html document
rmarkdown::render("outcome-tables.Rmd", output_format = rmarkdown::html_document(toc = TRUE))
```

The html document can then be compiled as pdf using pandoc from the command line:

```{bash}  
pandoc outcome-tables.html -o outcome-tables.pdf --pdf-engine=weasyprint
```

## Access data from gt table object

```{r}
gt.table <- tables[[1]][[1]]
str(gt.table$`_data`, max.level = 1)
inline_outcome_text <- function(gt.table, outcome, level, column) {
    ## Define borrowed functions
    `%>%` <- magrittr::`%>%`
    pull <- dplyr::pull

    ## Check arguments
    assertthat::assert_that(
        "gt_tbl" %in% class(gt.table),
        is.character(outcome),
        is.character(level),
        is.character(column) | is.numeric(column)
    )

    ## Extract data
    gt.data <- gt.table$`_data`
    outcome.index <- na.omit(gt.table$`_styles`$rownum) # This relies on outcome names being styled as bold
    valid.outcomes <- gt.data$Outcome[outcome.index]
    outcome.pos <- grep(paste0("^", outcome, "$"), valid.outcomes)

    ## Stop if outcome not found
    if (length(outcome.pos) == 0) {
        stop(
            "No outcome found for outcome ",
            outcome,
            ". Choose one from c(",
            paste0(paste0("\"", valid.outcomes, "\""), collapse = ", "), ")."
        )
    }

    ## Extract only the relevant part of the table
    first.row <- outcome.index[outcome.pos] + 1
    if (outcome.pos == rev(outcome.index)[1]) {
        last.row <- nrow(gt.data)
    } else {
        last.row <- outcome.index[outcome.pos + 1] - 1
    }
    outcome.limits <- c(first.row, last.row)
    outcome.subtable <- gt.data[outcome.limits[1]:outcome.limits[2], ]

    ## Stop if column not found
    if (!is.numeric(column)) {
        new.column <- grep(column, names(outcome.subtable))
        if (length(new.column) > 1) {
            stop(
                "More than one column found for column ",
                column,
                ". Choose one from c(",
                paste0(paste0("\"", names(outcome.subtable), "\""), collapse = ", "), ")."
            )
        }
        if (length(new.column) == 0) {
            stop(
                "No column found for column ",
                column,
                ". Choose one from c(",
                paste0(paste0("\"", names(outcome.subtable), "\""), collapse = ", "), ")."
            )
        }
    }

    ## Stop if level not found
    new.level <- grep(level, outcome.subtable$Outcome)
    if (length(new.level) > 1) {
        stop(
            "More than one level found for level ",
            level,
            ". Choose one from c(",
            paste0(paste0("\"", outcome.subtable$Outcome, "\""), collapse = ", "), ")."
        )
    }
    if (length(new.level) == 0) {
        stop(
            "No level found for level ",
            level,
            ". Choose one from c(",
            paste0(paste0("\"", outcome.subtable$Outcome, "\""), collapse = ", "), ")."
        )
    }

    ## Extract inline text
    outcome.text <- outcome.subtable[outcome.subtable$Outcome == level, new.column] %>%
        pull() %>%
        unlist()

    ## Return inline text
    return(outcome.text)
}
gt.table$`_data`
gt.table$`_styles`
```

## Playground

```{r}
boot.files <- list.files("out")
length(boot.files)
```

## Create data report

```{r}
DataExplorer::create_report(data, report_title = "Data report", output_file = "data-report.pdf")
```

## Errors when running bootstrap on real data

1. I first got this strange error when I try to run the bootstrap on the real data:

```{r}
## Error in `add_column()`:
## ! New columns must be compatible with `.data`.
## <U+2716> New column has 112 rows.
## <U+2139> `.data` has 111 rows.
## Backtrace:
##     <U+2586>
##  1. <U+251C><U+2500>boot::boot(data, estimate_outcome_results, R = n.boot.samples)
##  2. <U+2502> <U+2514><U+2500>global statistic(data, original, ...)
##  3. <U+2502>   <U+2514><U+2500>outcomes.tables$absolute.difference %>% as_tibble() %>% ...
##  4. <U+2514><U+2500>tibble::add_column(., outcomes.row.names, .before = 1)
##  5.   <U+2514><U+2500>tibble:::abort_incompatible_new_cols(nrow(.data), df)
##  6.     <U+2514><U+2500>tibble:::tibble_abort(...)
##  7.       <U+2514><U+2500>rlang::abort(x, class, ..., call = call, parent = parent, use_cli_format = TRUE)
## Execution halted
```

The cause of the error is the entry 995 in the variable `complications__number_of_hospitalizations_for_this_injury`. Not sure where that entry comes from, but most likely it should be 999 but something went wrong? A quick fix is to replace this value with 999 in the `prepare_data` function, which should work.

2. I then got this error:

```{r}
## Error in Ops.data.frame(outcomes.tables$post.training[2:4], outcomes.tables$pre.training[2:4]) :
##   <U+2018>-<U+2019> only defined for equally-sized data frames
## Calls: boot -> statistic -> Ops.data.frame
## Execution halted
```

This was because the three different datasets, one for overall, one for pre-training and one for post-training, were not the same size. The reason was that there were different but small numbers of unique values in some variables that should be treated as numeric but that was instead treated as categorical by tbl_summary. Ensuring that these were in fact treated as numeric solved the issue.

## Generate synthetic data

Because developing on the server is generally slow, a first step to speed up development was to generate a synthetic dataset that could be safely used locally. Check [main.R](./main.R) to make sure that `data` is in the correct state before creating the synthetic data using the code below.

```{r, synthetic-data-generation}
## Generate synthetic data. For each column, sample from the same distribution as the original data, but do not keep correlations present in the orginal data.
synth.data <- lapply(data, function(column) {
    if (is.factor(column)) {
        return(as.factor(sample(levels(column), size = length(column), replace = TRUE)))
    } else if (is.character(column)) {
        return(as.character(sample(column, size = length(column), replace = TRUE)))
    } else if (is.numeric(column)) {
        return(rnorm(n = length(column), mean = mean(column, na.rm = TRUE), sd = sd(column, na.rm = TRUE)))
    } else if (is.logical(column)) {
        return(sample(c(TRUE, FALSE), size = length(column), replace = TRUE))
    } else if (is.POSIXct(column) | is.POSIXt(column)) {
        return(as.POSIXct(sample(as.numeric(column), size = length(column), replace = TRUE), origin = "1970-01-01"))
    } else {
        return(rep(NA, length(column)))
    }
}) %>% as.data.frame()

## Replace values in columns with character values with random strings
synth.data[, sapply(synth.data, is.character)] <- lapply(synth.data[, sapply(synth.data, is.character)], function(column) {
    n.unique <- length(unique(column))
    new.values <- replicate(n.unique, paste(sample(letters, size = 10, replace = TRUE), collapse = ""))
    new.values <- rep(new.values, length.out = length(column))
    return(new.values)
})

## Replace values in any variable with id in the name random numbers
id.vars <- c("X_id", "id__reg_hospital_id", "id__assigned_patient_id", "meta__instanceID", "meta__deprecatedID", "formhub__uuid", "X_xform_id_string", "X_uuid")
synth.data[, id.vars] <- lapply(synth.data[, id.vars], function(column) {
    n.unique <- length(unique(column))
    new.values <- rep(sample(1:1e6, size = n.unique, replace = FALSE), length.out = length(column))
    return(new.values)
})

## Check that no rows in the original data are present in the synthetic data
stopifnot(!any(pbapply(data, 1, function(row) {
    any(apply(synth.data, 1, function(synth.row) {
        all(row == synth.row, na.rm = TRUE)
    }))
})))

## Put labels back
synth.data <- synth.data %>% labelled::copy_labels_from(data)

## Create data report
DataExplorer::create_report(synth.data, report_title = "Synthetic data report", output_file = "synth-data-report.html")

## Encrypt synthetic data before writing to file
key <- sha256(charToRaw(Sys.getenv("SYNTH_DATA_KEY")))
encrypted.synth.data <- aes_cbc_encrypt(serialize(synth.data, NULL), key = key)

## Write synthetic data to file
saveRDS(encrypted.synth.data, file = "data/synth-data.rds")

## Encrypt and write codebook to file, but first remove the settings entry
codebook$settings <- NULL
encrypted.codebook <- aes_cbc_encrypt(serialize(codebook, NULL), key = key)
saveRDS(encrypted.codebook, file = "data/codebook.rds")
```

To develop locally both the data and the codebook need to be loaded.

```{r load-data}
key <- sha256(charToRaw(Sys.getenv("SYNTH_DATA_KEY")))
data <- unserialize(aes_cbc_decrypt(readRDS("data/synth-data.rds"), key = key))
codebook <- unserialize(aes_cbc_decrypt(readRDS("data/codebook.rds"), key = key))
```

Probably a good idea to wrap the generation of these results into a function, and introduce a test argument, to prevent us from introducing local results in the main manuscript.

```{r basic-results}
get_basic_results <- function(test = FALSE) {
    results <- list()
    ## Define basic results
    arrival.dates <- data %>%
        pull(incident__date_of_arrival) %>%
        as.Date()
    results$start.date <- arrival.dates %>%
        min() %>%
        format_date()
    results$end.date <- arrival.dates %>%
        max() %>%
        format_date()
    n.no.consent <- list(
        "11542" = 40,
        "44805" = 10,
        "55356" = 43,
        "78344" = 3,
        "95846" = 9,
        "88456" = 0, # To be updated
        "10263" = 2
    )
    results$icc <- estimate_icc("outcomes__discharge_alive", "id__reg_hospital_id", data)
    results$n.patients <- nrow(data)
    results$n.atls.residents <- 4 + 2 # The total number of residents trained in ATLS, per ATLS centre
    results$n.ptc.residents <- 9 + 6 # The total number of residents trained in PTC, per centre
    results$n.residents <- with(results, n.atls.residents + n.ptc.residents)
    results$n.centres <- data %>%
        pull(id__reg_hospital_id) %>%
        unique() %>%
        length()
    results$n.atls <- sum(data$arm == "ATLS")
    results$n.ptc <- sum(data$arm == "PTC")
    results$n.control <- sum(data$arm == "Standard care")
    results$n.females <- with(data, sum(patinfo__pt_gender == "Female"))
    results$p.females <- round(results$n.females / nrow(data) * 100)
    results$median.age <- median(data$patinfo__pt_age, na.rm = TRUE)
    results$iqr.age <- get_iqr(data$patinfo__pt_age)
    results$median.iss <- median(data$riss, na.rm = TRUE)
    results$iqr.iss <- get_iqr(data$riss)
    results$median.niss <- median(data$niss, na.rm = TRUE)
    results$iqr.niss <- get_iqr(data$niss)
    results$n.admitted <- with(data, sum(interventions__admitted == "Yes"))
    results$p.admitted <- round(results$n.admitted / nrow(data) * 100)
    return(results)
}
```

Cutting code from the main script and putting it here for future reference:

```{r}
## Calculate outcome results
n.m30d <- with(data, sum(outcomes__alive_after_30_days == "Yes", na.rm = TRUE))
p.m30d <- round(n.m30d / nrow(data) * 100)
arms.n.m30d.list <- lapply(
    setNames(arms.data.list, nm = paste0("m30d.", names(arms.data.list))),
    function(arms.data) {
        with(
            arms.data,
            sum(outcomes__alive_after_30_days == "Yes", na.rm = TRUE)
        )
    }
)
arms.p.m30d.list <- mapply(arms.n.m30d.list, arms.data.list,
    FUN = function(count, arms.data) list(round(count / nrow(arms.data) * 100))
)
names(arms.n.m30d.list) <- paste0("n.", names(arms.n.m30d.list))
names(arms.p.m30d.list) <- paste0("p.", names(arms.p.m30d.list))
attach(arms.n.m30d.list)
attach(arms.p.m30d.list)
arr.atls.ptc <- p.m30d.atls - p.m30d.ptc
arr.atls.control <- p.m30d.atls - p.m30d.control
arr.ptc.control <- p.m30d.ptc - p.m30d.control
rr.atls.ptc <- round(p.m30d.atls / p.m30d.ptc, 2)
rr.atls.control <- round(p.m30d.atls / p.m30d.control, 2)
rr.ptc.control <- round(p.m30d.ptc / p.m30d.control, 2)
p.missing.in.hospital.mortality <- round(sum(is.na(data$outcomes__discharge_alive)) / n.patients * 100)

## Estimate composite outcome
in.hospital.mortality <- data$outcomes__discharge_alive == "Yes"
data$in.hospital.mortality <- in.hospital.mortality
icc.in.hospital.mortality <- estimate_icc("in.hospital.mortality", "id__reg_hospital_id", data)
labelled::var_label(data$in.hospital.mortality) <- "In-hospital mortality"
confined.to.bed <- data$outcomes__eq5dm == "I am confined to bed"
data$confined.to.bed <- confined.to.bed
labelled::var_label(data$confined.to.bed) <- "Confined to bed"
extreme.pain.discomfort <- data$outcomes__eq5dpd == "I have extreme pain or discomfort"
data$extreme.pain.discomfort <- extreme.pain.discomfort
labelled::var_label(data$extreme.pain.discomfort) <- "Extreme pain or discomfort"
unable.bath.dress <- data$outcomes__eq5dsc == "I am unable to bathe or dress myself"
data$unable.bath.dress <- unable.bath.dress
labelled::var_label(data$unable.bath.dress) <- "Unable to bathe or dress oneself"
unable.usual.activities <- data$outcomes__eq5dua == "I am unable to perform my usual activities"
data$unable.usual.activities <- unable.usual.activities
labelled::var_label(data$unable.usual.activities) <- "Unable to perform usual activities"
composite.outcome <- in.hospital.mortality |
    confined.to.bed |
    extreme.pain.discomfort |
    unable.bath.dress |
    unable.usual.activities
data$composite.outcome <- composite.outcome
labelled::var_label(data$composite.outcome) <- "Composite endpoint"
n.composite.outcome <- sum(composite.outcome, na.rm = TRUE)
p.composite.outcome <- round(n.composite.outcome / nrow(data) * 100)
icc.composite.outcome <- estimate_icc("composite.outcome", "id__reg_hospital_id", data)

## Resident outcomes
median.confidence <- median(as.numeric(data$resident__res_comfort), na.rm = TRUE)
iqr.confidence <- quantile(as.numeric(data$resident__res_comfort), probs = c(0.25, 0.75), na.rm = TRUE) %>%
    paste0(collapse = "-")

## Feasibility outcomes

## List of potentially eligible patient participants per site, replace
## IDs with actual IDs once known and replace figures with actual
## figures once known
n.potentially.eligible <- list(
    n.potentially.eligible.centre.1 = 999,
    n.potentially.eligible.centre.2 = 999,
    n.potentially.eligible.centre.3 = 999,
    n.potentially.eligible.centre.4 = 999,
    n.potentially.eligible.centre.5 = 999,
    n.potentially.eligible.centre.6 = 999,
    n.potentially.eligible.centre.7 = 999
)
recruitment.rate.patients <- round(n.patients / do.call(sum, n.potentially.eligible) * 100)
n.eligible.residents <- 21
recruitment.rate.residents <- round(n.residents / n.eligible.residents * 100)
n.lost.to.follow.up <- sum(is.na(data$outcomes__alive_after_30_days))
rate.lost.to.follow.up <- round(n.lost.to.follow.up / n.patients * 100)
n.atls.residents.passed.first.attempt <- 2 + 2 # The number of residents who had passed ATLS after the first attempt, per centre
n.atls.residents.passed.second.attempt <- 4 + 2 # The number of residents who had passed ATLS after the second attempt, per centre
rate.pass <- round((n.atls.residents.passed.second.attempt + n.ptc.residents) / n.residents * 100)
rates.missing.data <- unlist(lapply(data, function(column) round(sum(is.na(column) / length(column) * 100))))
min.missing.data <- min(rates.missing.data)
max.missing.data <- max(rates.missing.data)

## Calculate varying cluster sizes
cluster.sizes <- sapply(centre.ids, function(centre.id) nrow(data[data$id__reg_hospital_id == centre.id, ]))
sd.cluster.size <- sd(cluster.sizes)
mean.cluster.size <- mean(cluster.sizes)
ratio.sd.mean.cluster.size <- sd.cluster.size / mean.cluster.size
```
